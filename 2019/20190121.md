# 21 January 2019

Recursion trips a lot of people up.
I'm not convinced that recursion is a genuinely complicated concept.
Lately, I wonder if the way recursion is explained is largely responsible for the
confusion.

There are actually two mental models for recursion that I've encountered.
First, recursion is looping.
This was how I was introduced to recursion in JavaScript.
Introductions to functional programming said that loops were bad because they're
imperative.
The problem with lists specifically is two things: 1. they're not composable
and 2. they can have side-effects.
But programmers need a way to iterate. 
So this was the motivation for recursion.
When you would use a loop, use function recursion instead.

The second mental model for recursion is to walk throught the evaluation of a 
recursive function.
This is the approach taken by The Little Schemer.
I think there is some value in tracing the execution of a recursive function.
But I think this is an overwhelming introduction to the concept of recursion.
Tracing evaluation requires you maintain a mental model of the call stack.
You evaluate the first function call to the point of recursion, then start 
evaluating the second function call, and so on until you reach the base case.
Then you work backwords, combinining the result of each function call (hope you 
still remember them all) into the final result.

The mental model that I've settled on is not related principally about iteration
or about a stack of function calls.
To me, recursion is substitution.
This mental model begins with the concept of referential transparency.
Referential transparency is the property of functions that can be replaced with 
its output.
The function `upperCase('a')` is equivalent to the value `'A'`.
Anywhere that `upperCase('a')` is found in a program, the function call can be
just substituted with `'A'` without actually evaluating the function.
That's because the function will always return `'A'` and because the function 
does not have side-effects.

So upperCase is an arrow from `'a' -> 'A'`, `'b' -> 'B'`, etc.
Now what if I have a list `['a', 'b', 'c']` and I want to turn that into a list
of `['A', 'B', 'C']`?

Recursive functions, in a pure setting, are just about substituting f(x) for y.
So I know how to get 'A' from 'a'.
Now what if I have a list of `['a', 'b', 'c']` and I want a list of 
`['A', 'B', 'C"]`?
The intuition of subsituting function calls with concrete values should lead me
to think of that as `[upperCase('a'), upperCase('b'), upperCase('c')]`.
We have three calls of `upperCase`.
We can reason about each call without any more mental overhead than our first example.
There is not added context, no order of operations, no more information required to
know the result of each function call.
That this function calls exist in a list doesn't mean anything.

Ok, so we can define a list literal like that.
But how do we apply that function to items in a existing list?
Let's introduce the function map.
Map takes a function and a list, and applies the function to every item in the 
list, returning the result.

```haskell
map :: (a -> b) -> [a] -> [b]
map upperCase ['a', 'b', 'c'] -- ['A', 'B', 'C']
```

Good enough. But how does map do that?
Let's remind ourselves of this concept of referential transparency.

```haskell
upperCaseChars :: [Char] -> [Char]
upperCaseChars = map upperCase

-- upperCaseChars ['a', 'b', 'c'] -> ['A', 'B', 'C'] 
-- upperCaseChars ['b', 'c'] -> ['B', 'C'] 
-- upperCaseChars ['c'] -> ['C'] 
-- upperCaseChars [] -> [] 
```

Ok so now we have a function that substitutes 'a' for 'A'.
And we have a function that substitutes ['a', 'b', 'c'] with ['A', 'B', 'C'].
So now we can define 

We know that `upperCaseChars ['a', 'b', 'c']` can always be replaced with the 
concrete value `['A', 'B', 'C']`. 
And `upperCaseChars ['b', 'c']` can always be replaced with `['B','C']`.
And so on.
So let's try to think of recursion not as looping or nested function calls.
Let's try to think of recursion as just like every other kind of function call - 
a substitution of an expression for a concrete value.

So, when we're mapping over a list, we do three things:
1. apply the function to the first item in the list
2. substitute the rest of the list with `map f rest`.
3. Combining f(x) and the new list.

```haskell
map f [] = []
map f (x:tail) = cons (f x) (map f tail)
```

Why does this make sense?
Because f x is upperCase 'a' is 'A' and map f tail is map upperCase ['b', 'c']
can be substituted for ['B', 'C'].
And 'A' : ['B', 'C'] can be substituted for ['A', 'B', 'C'].

In this mental model, recursion is not a special case of function application,
where calling a function once implicitly calls that function n times.
Of course, that is what happens when the function is evaluated.
But we don't have to keep track of all that in our heads.
We just think that "I want to replace a function application with a concrete 
value".
When I have many values, I replace the "first value with a function application".
Then I replace "the rest of the list with a function application".
When I have replaced those function applications with concrete values, then I 
can combine them into a new list.
